<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <title>E-Waste Detector (Mobile & Desktop)</title>

  <!-- Tailwind CSS -->
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>

  <style>
    html, body {
      height: 100%;
      margin: 0;
      overflow: hidden;
      font-family: 'Inter', sans-serif;
      background-color: #000;
    }
    #webcam, #canvas {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      object-fit: cover;
    }
    #loader-container {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      background: rgba(0, 0, 0, 0.85);
      z-index: 99;
      color: white;
    }
    .loader {
      border: 4px solid rgba(255, 255, 255, 0.3);
      border-top: 4px solid #10b981;
      border-radius: 50%;
      width: 40px; height: 40px;
      animation: spin 1s linear infinite;
    }
    @keyframes spin { to { transform: rotate(360deg); } }
    #cameraBtn {
      position: absolute;
      bottom: 50px;
      left: 50%;
      transform: translateX(-50%);
      z-index: 100;
    }
  </style>
</head>

<body class="text-white">

  <!-- Loader -->
  <div id="loader-container">
    <div class="loader"></div>
    <p id="loader-text" class="mt-4 text-lg">Loading model...</p>
  </div>

  <!-- Main Elements -->
  <video id="webcam" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>

  <button id="cameraBtn"
          class="px-6 py-4 bg-blue-600 font-semibold rounded-lg shadow-lg hover:bg-blue-700 transition duration-300 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50">
    Start Camera
  </button>

  <script>
    const video = document.getElementById('webcam');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const loaderContainer = document.getElementById('loader-container');
    const loaderText = document.getElementById('loader-text');
    const cameraBtn = document.getElementById('cameraBtn');

    let model = null;
    const classNames = ['Battery', 'Cable', 'PCB'];
    const colors = ['#FF3838', '#FF9D97', '#FF701F'];
    const modelSize = 640;
    const scoreThreshold = 0.3;
    const iouThreshold = 0.45;

    /* ------------------ MODEL LOADING ------------------ */
    async function loadModel() {
      try {
        const modelPath = 'best_web_model/model.json';  // relative path
        loaderText.innerText = 'Loading YOLO model...';
        model = await tf.loadGraphModel(modelPath);

        // Optimize WebGL to reduce memory leaks
        tf.env().set('WEBGL_DELETE_TEXTURE_THRESHOLD', 0);
        tf.env().set('WEBGL_FLUSH_THRESHOLD', 0);
        tf.env().set('WEBGL_FORCE_F16_TEXTURES', true);
        tf.env().set('WEBGL_PACK_DEPTHWISECONV', false);

        // Warm-up pass
        tf.tidy(() => model.execute(tf.zeros([1, modelSize, modelSize, 3])));
        console.log('âœ… Model loaded successfully');
        loaderContainer.classList.add('hidden');
      } catch (err) {
        console.error('âŒ Failed to load model:', err);
        loaderText.innerText = 'Error loading model (see console).';
      }
    }

    /* ------------------ CAMERA INIT ------------------ */
    async function startWebcam() {
      try {
        const constraints = {
          video: {
            facingMode: { ideal: "environment" }, // back camera on phones
            width: { ideal: 640 },
            height: { ideal: 480 }
          },
          audio: false
        };

        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
        cameraBtn.classList.add('hidden');

        video.onloadeddata = () => {
          if (video.videoWidth === 0 || video.videoHeight === 0) {
            console.warn('â³ Waiting for first frame...');
            requestAnimationFrame(video.onloadeddata);
            return;
          }
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          console.log(`ðŸŽ¥ Camera ready: ${canvas.width}Ã—${canvas.height}`);
          detectFrame();
        };
      } catch (err) {
        console.error('âš ï¸ Camera initialization failed:', err);
        loaderText.innerText = 'Camera access denied or unavailable.';
        cameraBtn.classList.remove('hidden');
      }
    }

    /* ------------------ DETECTION LOOP ------------------ */
    async function detectFrame() {
      if (!model) {
        requestAnimationFrame(detectFrame);
        return;
      }

      try {
        const [inputTensor, scale, pad] = preprocessFrame(video, modelSize);
        const output = model.execute(inputTensor);
        const [boxes, scores, classes] = processOutput(output);

        const indices = await tf.image.nonMaxSuppressionAsync(
          boxes, scores, 20, iouThreshold, scoreThreshold
        );

        const selBoxes = tf.gather(boxes, indices);
        const selScores = tf.gather(scores, indices);
        const selClasses = tf.gather(classes, indices);

        const boxesArr = selBoxes.arraySync();
        const scoresArr = selScores.arraySync();
        const classesArr = selClasses.arraySync();

        drawBoxes(boxesArr, scoresArr, classesArr, scale, pad);

        tf.dispose([inputTensor, output, boxes, scores, classes,
                    indices, selBoxes, selScores, selClasses]);
        await tf.nextFrame();

      } catch (err) {
        if (!String(err).includes('0x0')) console.error('âš ï¸ Detection error:', err);
      }

      // 100â€“150 ms delay for smoother FPS on mobile
      await new Promise(r => setTimeout(r, 120));
      requestAnimationFrame(detectFrame);
    }

    /* ------------------ HELPER FUNCTIONS ------------------ */
    function preprocessFrame(video, size) {
      const vidW = video.videoWidth, vidH = video.videoHeight;
      if (vidW === 0 || vidH === 0) return [tf.zeros([1, size, size, 3]), 1, [0, 0]];

      const scale = Math.min(size / vidW, size / vidH);
      const newW = Math.round(vidW * scale), newH = Math.round(vidH * scale);
      const padW = (size - newW) / 2, padH = (size - newH) / 2;

      const img = tf.browser.fromPixels(video)
        .resizeBilinear([newH, newW])
        .div(255.0)
        .pad([[Math.floor(padH), Math.ceil(padH)],
              [Math.floor(padW), Math.ceil(padW)], [0, 0]])
        .expandDims(0);

      return [img, scale, [padW, padH]];
    }

    function processOutput(out) {
      const t = out.transpose([0, 2, 1]).squeeze(0);
      const boxes = t.slice([0, 0], [-1, 4]);
      const classProbs = t.slice([0, 4], [-1, -1]);
      const scores = classProbs.max(1);
      const classes = classProbs.argMax(1);

      const [cx, cy, w, h] = boxes.split([1, 1, 1, 1], 1);
      const x1 = cx.sub(w.div(2)), y1 = cy.sub(h.div(2)),
            x2 = cx.add(w.div(2)), y2 = cy.add(h.div(2));
      const finalBoxes = tf.concat([y1, x1, y2, x2], 1);
      return [finalBoxes, scores, classes];
    }

    function drawBoxes(boxesArr, scoresArr, classesArr, scale, pad) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.lineWidth = 3;
      ctx.font = '16px Arial';

      for (let i = 0; i < boxesArr.length; i++) {
        const [y1, x1, y2, x2] = boxesArr[i];
        const id = classesArr[i];
        const score = scoresArr[i];
        const color = colors[id % colors.length];

        // Undo letterbox scaling
        const bx = (x1 - pad[0]) / scale;
        const by = (y1 - pad[1]) / scale;
        const bw = (x2 - x1) / scale;
        const bh = (y2 - y1) / scale;

        const x = bx * (canvas.width / video.videoWidth);
        const y = by * (canvas.height / video.videoHeight);
        const width = bw * (canvas.width / video.videoWidth);
        const height = bh * (canvas.height / video.videoHeight);

        ctx.strokeStyle = color;
        ctx.strokeRect(x, y, width, height);

        const label = `${classNames[id]}: ${(score * 100).toFixed(1)}%`;
        const tw = ctx.measureText(label).width;
        ctx.fillStyle = color;
        ctx.fillRect(x, y - 20, tw + 10, 20);
        ctx.fillStyle = '#000';
        ctx.fillText(label, x + 5, y - 5);
      }
    }

    /* ------------------ INIT ------------------ */
    window.addEventListener('load', loadModel);
    cameraBtn.addEventListener('click', startWebcam);
  </script>
</body>
</html>
