<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <!-- 1. Viewport tag is CRITICAL for mobile responsiveness -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>E-Waste Detector (Mobile)</title>

    <link rel="icon" href="data:,">

    <!-- 2. Load Tailwind CSS for easy, clean styling -->
    <script src="https://cdn.tailwindcss.com"></script>

    <!-- 3. Load TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>

    <style>
        /* Make the app feel more "native" */
        html,
        body {
            height: 100%;
            overflow: hidden;
            font-family: 'Inter', sans-serif;
        }

        body {
            background-color: #000;
        }

        /* Custom style to overlay canvas on top of video */
        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 10;
        }

        #webcam {
            width: 100%;
            height: 100%;
            object-fit: cover;
            /* Fill the whole screen */
        }

        /* Simple loader animation */
        @keyframes spin {
            to {
                transform: rotate(360deg);
            }
        }

        .loader {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-top: 4px solid #3498db;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
        }

        /* Full-screen loader overlay */
        #loader-container {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            z-index: 99;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            color: white;
        }

        /* Button style */
        #cameraBtn {
            position: absolute;
            bottom: 50px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 100;
        }
    </style>
</head>

<body class="text-white">

    <!-- Loading Indicator -->
    <div id="loader-container">
        <div class="loader"></div>
        <p id="loader-text" class="mt-4 text-lg">Loading model...</p>
    </div>

    <!-- Main Content -->
    <div id="main-content" class="relative w-full h-full">
        <!-- 
          4. 'playsinline' is CRITICAL for iOS to prevent fullscreen.
        -->
        <video id="webcam" autoplay playsinline muted class="w-full h-full"></video>
        <canvas id="canvas"></canvas>
    </div>

    <!-- Button to start camera -->
    <button id="cameraBtn"
        class="px-6 py-4 bg-blue-600 font-semibold rounded-lg shadow-lg hover:bg-blue-700 transition duration-300 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50">
        Start Camera
    </button>
    <p id="status" class="hidden"></p> <!-- For debugging -->


    <script>
        const video = document.getElementById('webcam');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const loaderContainer = document.getElementById('loader-container');
        const loaderText = document.getElementById('loader-text');
        const cameraBtn = document.getElementById('cameraBtn');

        let model = null;

        const classNames = ['Battery', 'Cable', 'PCB'];
        const colors = ['#FF3838', '#FF9D97', '#FF701F'];
        const modelWidth = 640, modelHeight = 640;
        const scoreThreshold = 0.25, iouThreshold = 0.45;

        async function loadModel() {
            try {
                const modelPath = './best_web_model/model.json?v=3.0';
                model = await tf.loadGraphModel(modelPath);
                // Optimize for mobile GPU
                tf.env().set('WEBGL_DELETE_TEXTURE_THRESHOLD', 0);
                tf.env().set('WEBGL_FLUSH_THRESHOLD', 0);
                tf.env().set('WEBGL_FORCE_F16_TEXTURES', true);

                // warm up
                tf.tidy(() => model.execute(tf.zeros([1, modelWidth, modelHeight, 3])));
                console.log('‚úÖ Model loaded.');
                loaderContainer.classList.add('hidden');
                loaderContainer.style.display = 'none';

            } catch (err) {
                console.error('‚ùå Failed to load model:', err);
                loaderText.innerText = 'Error loading model. See console.';
            }
        }

        async function startWebcam() {
            try {
                const constraints = { video: { facingMode: 'environment', width: { ideal: 1280 }, height: { ideal: 720 } }, audio: false };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                cameraBtn.classList.add('hidden');
                video.onloadedmetadata = () => {
                    // Ensure the video feed is actually streaming frames
                    function checkReady() {
                        if (video.videoWidth === 0 || video.videoHeight === 0) {
                            console.warn('‚è≥ Waiting for first video frame...');
                            requestAnimationFrame(checkReady);
                            return;
                        }

                        // Once ready, set correct canvas size
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;

                        console.log(`üé• Camera ready: ${canvas.width}x${canvas.height}`);

                        // Hide the loader overlay once the camera feed is ready
                        loaderContainer.classList.add('hidden');

                        // Start detection
                        detectFrame();

                    }
                    checkReady();
                };

            } catch (err) {
                console.error('Camera error:', err);
                cameraBtn.classList.remove('hidden');
            }
        }

        async function detectFrame() {
            if (video.videoWidth === 0 || video.videoHeight === 0) {
                requestAnimationFrame(detectFrame);
                return;
            }

            if (!model) {
                requestAnimationFrame(detectFrame);
                return;
            }

            try {
                // Wrap everything in tf.tidy to auto-dispose internal tensors each frame
                const results = tf.tidy(() => {
                    const input = tf.browser.fromPixels(video)
                        .resizeBilinear([modelWidth, modelHeight])
                        .div(255.0)
                        .expandDims(0);

                    const output = model.execute(input);
                    console.log('üîç Output shape:', output.shape);
                    const [boxes, scores, classes] = processOutput(output);

                    // NMS runs asynchronously, so don't include it inside tidy()
                    return { boxes, scores, classes };
                });

                const indices = await tf.image.nonMaxSuppressionAsync(
                    results.boxes, results.scores, 10, iouThreshold, scoreThreshold
                );

                // gather selected boxes outside tidy (still need them after)
                const selBoxes = tf.gather(results.boxes, indices);
                const selScores = tf.gather(results.scores, indices);
                const selClasses = tf.gather(results.classes, indices);

                const boxesArr = selBoxes.arraySync();
                const scoresArr = selScores.arraySync();
                const classesArr = selClasses.arraySync();

                drawBoxes(boxesArr, scoresArr, classesArr);

                // Clean up any tensors created outside tidy()
                tf.dispose([indices, selBoxes, selScores, selClasses]);
                await tf.nextFrame();

                // Debug memory occasionally
                if (Math.random() < 0.02) {
                    const mem = tf.memory();
                    console.log(`üîπ Active tensors: ${mem.numTensors}, GPU mem: ${(mem.numBytes / 1e6).toFixed(1)} MB`);
                }
            } catch (err) {
                console.error('‚ö†Ô∏è Detection error:', err);
            }

            requestAnimationFrame(detectFrame);
        }


        function processOutput(out) {
            // YOLOv8 TFJS output shape: [1, 7, 8400] ‚Üí [8400, 7]
            const t = out.squeeze(0).transpose([1, 0]); // from [7, 8400] to [8400, 7]

            // Split into 4 box coords + 3 class scores
            let [x, y, w, h, conf1, conf2, conf3] = tf.split(t, [1, 1, 1, 1, 1, 1, 1], 1);

            // Apply sigmoid to normalize values
            x = x.sigmoid();
            y = y.sigmoid();
            w = w.sigmoid();
            h = h.sigmoid();

            const classProbs = tf.concat([conf1, conf2, conf3], 1).sigmoid();
            const scores = classProbs.max(1);
            const classes = classProbs.argMax(1);

            // Convert [cx, cy, w, h] ‚Üí [y1, x1, y2, x2]
            const x1 = x.sub(w.div(2));
            const y1 = y.sub(h.div(2));
            const x2 = x.add(w.div(2));
            const y2 = y.add(h.div(2));

            const finalBoxes = tf.concat([y1, x1, y2, x2], 1);
            return [finalBoxes, scores, classes];
        }

        function drawBoxes(boxesArr, scoresArr, classesArr) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            for (let i = 0; i < boxesArr.length; i++) {
                const [ymin, xmin, ymax, xmax] = boxesArr[i];
                const x = xmin * canvas.width;
                const y = ymin * canvas.height;
                const width = (xmax - xmin) * canvas.width;
                const height = (ymax - ymin) * canvas.height;

                const id = classesArr[i];
                const score = scoresArr[i].toFixed(2);
                const label = `${classNames[id]}: ${score}`;
                const color = colors[id];

                ctx.strokeStyle = color;
                ctx.lineWidth = 3;
                ctx.strokeRect(x, y, width, height);

                ctx.fillStyle = color;
                const textWidth = ctx.measureText(label).width;
                ctx.fillRect(x, y - 20, textWidth + 10, 20);

                ctx.fillStyle = '#000';
                ctx.font = '16px Arial';
                ctx.fillText(label, x + 5, y - 5);
            }
        }

        window.addEventListener('load', loadModel);
        cameraBtn.addEventListener('click', startWebcam);
        window.addEventListener('resize', () => {
            if (video.srcObject) {
                canvas.width = video.clientWidth;
                canvas.height = video.clientHeight;
            }
        });
    </script>


</body>

</html>